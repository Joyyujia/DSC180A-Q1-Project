{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, LayerNorm, Sequential, BatchNorm1d, ModuleList\n",
    "from torch_geometric.datasets import IMDB\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.datasets import LRGBDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import GPSConv, GATv2Conv, GATConv, GINConv, GCNConv, global_add_pool, global_mean_pool\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "cora_dataset = Planetoid(root='./data/Cora', name='Cora', split='public')\n",
    "imdb_dataset = TUDataset(root='./data/IMDB-BINARY', name='IMDB-BINARY')\n",
    "enzyme_dataset = TUDataset(root='./data/Enzyme', name='ENZYMES')\n",
    "PascalVOC_dataset = LRGBDataset(root='/tmp/PascalVOC-SP', name='PascalVOC-SP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_data = cora_dataset[0]\n",
    "num_output_ch = 16\n",
    "learning_rate = 0.01\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, out_channels)\n",
    "        self.conv2 = GCNConv(out_channels, cora_dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN(cora_dataset.num_node_features, num_output_ch)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# train the model on Cora\n",
    "num_epochs = 200\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(cora_data)\n",
    "    loss = F.nll_loss(out[cora_data.train_mask], cora_data.y[cora_data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)\n",
    "\n",
    "# During training, record the accuracy on the validation set.\n",
    "model.eval()\n",
    "_, pred = model(cora_data).max(dim=1)\n",
    "correct = int(pred[cora_data.train_mask].eq(cora_data.y[cora_data.train_mask]).sum().item())\n",
    "accuracy = correct / cora_data.train_mask.sum().item()\n",
    "print(f'Train Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7780\n"
     ]
    }
   ],
   "source": [
    "# find accuracy on the test set\n",
    "_, pred = model(cora_data).max(dim=1)\n",
    "correct = int(pred[cora_data.test_mask].eq(cora_data.y[cora_data.test_mask]).sum().item())\n",
    "test_accuracy = correct / cora_data.test_mask.sum().item()\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GIN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora_data = cora_dataset[0]\n",
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GIN, self).__init__()\n",
    "        nn1 = torch.nn.Sequential(torch.nn.Linear(in_channels, out_channels), torch.nn.ReLU(), torch.nn.Linear(out_channels, out_channels))\n",
    "        nn2 = torch.nn.Sequential(torch.nn.Linear(out_channels, out_channels), torch.nn.ReLU(), torch.nn.Linear(out_channels, cora_dataset.num_classes))\n",
    "        \n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.conv2 = GINConv(nn2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "num_output_ch = 16\n",
    "learning_rate = 0.01\n",
    "gin_model = GIN(cora_dataset.num_node_features, num_output_ch)\n",
    "gin_optimizer = torch.optim.Adam(gin_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.0000, Val: 0.7380, Test: 0.7420\n"
     ]
    }
   ],
   "source": [
    "# train the model on Cora\n",
    "num_epochs = 150\n",
    "def train():\n",
    "    gin_model.train()\n",
    "    gin_optimizer.zero_grad()\n",
    "    out = gin_model(cora_data)\n",
    "    loss = F.nll_loss(out[cora_data.train_mask], cora_data.y[cora_data.train_mask])\n",
    "    loss.backward()\n",
    "    gin_optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    gin_model.eval()\n",
    "    logits, accs = gin_model(cora_data), []\n",
    "    for _, mask in cora_data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(cora_data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    train()\n",
    "    \n",
    "train_acc, val_acc, test_acc = test()\n",
    "print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GATv2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GATv2, self).__init__()\n",
    "        self.conv1 = GATv2Conv(in_channels, out_channels, heads=1)\n",
    "        self.conv2 = GATv2Conv(out_channels, cora_dataset.num_classes, heads=1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "gatv2_model = GATv2(cora_dataset.num_node_features, num_output_ch)\n",
    "gatv2_optimizer = torch.optim.Adam(gatv2_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.0000, Val: 0.7380, Test: 0.7420\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    gatv2_model.train()\n",
    "    gatv2_optimizer.zero_grad()\n",
    "    out = gatv2_model(cora_data)\n",
    "    loss = F.nll_loss(out[cora_data.train_mask], cora_data.y[cora_data.train_mask])\n",
    "    loss.backward()\n",
    "    gatv2_optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    gatv2_model.eval()\n",
    "    logits, accs = gatv2_model(cora_data), []\n",
    "    for _, mask in cora_data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(cora_data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train()\n",
    "    \n",
    "print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPS(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, pe_dim=8):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use linear layers for node embeddings and positional encodings\n",
    "        self.node_emb = Linear(in_channels, hidden_channels - pe_dim)\n",
    "        self.pe_lin = Linear(in_channels, pe_dim)\n",
    "        self.pe_norm = BatchNorm1d(in_channels)\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv_layer = GCNConv(hidden_channels, hidden_channels)\n",
    "            self.convs.append(GPSConv(hidden_channels, conv_layer))\n",
    "\n",
    "        self.mlp = Sequential(\n",
    "            Linear(hidden_channels, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        x = self.pe_norm(x)\n",
    "        x = torch.cat((self.node_emb(x), self.pe_lin(x)), 1)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index, batch=batch)  # Edge attributes are not passed\n",
    "        return F.log_softmax(self.mlp(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPS(in_channels=cora_dataset.num_node_features, hidden_channels=64, num_layers=3, out_channels=cora_dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train Acc: 1.0000, Final Test Acc: 0.5480\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(cora_data.x, cora_data.edge_index)\n",
    "    loss = F.nll_loss(out[cora_data.train_mask], cora_data.y[cora_data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = pred[cora_data.train_mask] == cora_data.y[cora_data.train_mask]\n",
    "    train_accuracy = int(correct.sum()) / int(cora_data.train_mask.sum())\n",
    "    \n",
    "    return train_accuracy\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(cora_data.x, cora_data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = pred[cora_data.test_mask] == cora_data.y[cora_data.test_mask]\n",
    "    return int(correct.sum()) / int(cora_data.test_mask.sum())\n",
    "\n",
    "num_epochs = 200\n",
    "final_train_acc, final_test_acc = None, None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_acc = train()\n",
    "    test_acc = test()\n",
    "    scheduler.step(train_acc)  # Note: This should ideally be a loss value\n",
    "\n",
    "    final_train_acc = train_acc\n",
    "    final_test_acc = test_acc\n",
    "\n",
    "# Print the final training and test accuracies\n",
    "print(f'Final Train Acc: {final_train_acc:.4f}, Final Test Acc: {final_test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enzyme Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joywang/opt/anaconda3/lib/python3.9/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Train test split on Enzyme data\n",
    "num_examples = len(enzyme_dataset)\n",
    "num_train = int(0.85 * num_examples)\n",
    "num_test = num_examples - num_train\n",
    "\n",
    "dataset = enzyme_dataset.shuffle()\n",
    "train_dataset = dataset[:num_train]\n",
    "test_dataset = dataset[num_train:]\n",
    "\n",
    "# Create dataloaders for train and test data\n",
    "bs = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
    "        super(GCNClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.fc = torch.nn.Linear(out_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch  # Include batch for batching\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)  # Apply global mean pooling\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_ch = 16\n",
    "learning_rate = 0.01\n",
    "model = GCNClassifier(in_channels=dataset.num_features, hidden_channels=num_hidden_ch, \n",
    "                      out_channels=num_output_ch, num_classes=dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, data.y)  # Cross-entropy loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.4745\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize variables to keep track of correct predictions and total examples\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "\n",
    "# Validation Set\n",
    "for data in train_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "        _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "        train_total += data.y.size(0)  # Increment the total count\n",
    "        train_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "        \n",
    "train_accuracy = train_correct / train_total\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4111\n"
     ]
    }
   ],
   "source": [
    "# Test Set\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "for data in test_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "    _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "    test_total += data.y.size(0)  # Increment the total count\n",
    "    test_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "    \n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GIN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return F.relu(x)\n",
    "\n",
    "class GINClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
    "        super(GINClassifier, self).__init__()\n",
    "        self.conv1 = GINConv(GNN(in_channels, hidden_channels))\n",
    "        self.conv2 = GINConv(GNN(hidden_channels, out_channels))\n",
    "        self.fc = torch.nn.Linear(out_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_ch = 16\n",
    "learning_rate = 0.01\n",
    "model = GINClassifier(in_channels=dataset.num_features, hidden_channels=num_hidden_ch, \n",
    "                      out_channels=num_output_ch, num_classes=dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, data.y)  # Cross-entropy loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6059\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize variables to keep track of correct predictions and total examples\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "\n",
    "# Validation Set\n",
    "for data in train_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "        _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "        train_total += data.y.size(0)  # Increment the total count\n",
    "        train_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "        \n",
    "train_accuracy = train_correct / train_total\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3444\n"
     ]
    }
   ],
   "source": [
    "# Test Set\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "for data in test_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "    _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "    test_total += data.y.size(0)  # Increment the total count\n",
    "    test_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "    \n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GAT2v Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATv2Classifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes, heads=1):\n",
    "        super(GATv2Classifier, self).__init__()\n",
    "        self.conv1 = GATv2Conv(in_channels, hidden_channels, heads=heads)\n",
    "        self.conv2 = GATv2Conv(hidden_channels * heads, out_channels, heads=heads)\n",
    "        self.fc = torch.nn.Linear(out_channels * heads, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GATv2Classifier(in_channels=dataset.num_features, hidden_channels=num_hidden_ch, \n",
    "                      out_channels=num_output_ch, num_classes=dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, data.y)  # Cross-entropy loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.4373\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize variables to keep track of correct predictions and total examples\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "\n",
    "# Validation Set\n",
    "for data in train_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "        _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "        train_total += data.y.size(0)  # Increment the total count\n",
    "        train_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "        \n",
    "train_accuracy = train_correct / train_total\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "# Test Set\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "for data in test_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "    _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "    test_total += data.y.size(0)  # Increment the total count\n",
    "    test_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "    \n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphGPS_ENZYMES(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes, num_layers, hidden_dim, heads, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input linear transformation\n",
    "        self.linear = Linear(num_features, hidden_dim)\n",
    "\n",
    "        # Define new_channels based on hidden_dim and heads\n",
    "        new_channels = hidden_dim\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv_layer = GATConv(hidden_dim, hidden_dim, heads=heads, dropout=dropout_rate, concat=False)\n",
    "            self.convs.append(GPSConv(new_channels, conv_layer))\n",
    "            self.norms.append(LayerNorm(new_channels))\n",
    "        \n",
    "        # Output linear layer\n",
    "        self.output = Linear(new_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            x = conv(x, edge_index)\n",
    "            x = norm(x)  # Apply LayerNorm\n",
    "            x = F.relu(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return F.log_softmax(self.output(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GraphGPS on train ENZYMES: 0.16666666666666666\n",
      "Accuracy of GraphGPS on test ENZYMES: 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "num_features = enzyme_dataset.num_features\n",
    "num_classes = enzyme_dataset.num_classes\n",
    "model = GraphGPS_ENZYMES(num_features, num_classes, num_layers=3, hidden_dim=128, heads=2, dropout_rate=0.5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training function for GraphGPS_ENZYMES\n",
    "def train_GPS(model, loader, optimizer):\n",
    "    model.train()\n",
    "    for data in loader:\n",
    "        data = data\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    train_GPS(model, train_dataset, optimizer)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data\n",
    "            out = model(data.x, data.edge_index, data.batch)\n",
    "            pred = out.max(dim=1)[1]\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "            y_pred.extend(pred.cpu().numpy())\n",
    "    correct = sum(t == p for t, p in zip(y_true, y_pred))\n",
    "    accuracy = correct / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "# Evaluate the model on the training and test data\n",
    "train_accuracy = evaluate(model, train_loader)\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print('Accuracy of GraphGPS on train ENZYMES:', train_accuracy)\n",
    "print('Accuracy of GraphGPS on test ENZYMES:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IBDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "num_examples = len(imdb_dataset)\n",
    "num_train = int(0.85 * num_examples)\n",
    "num_test = num_examples - num_train\n",
    "\n",
    "dataset = imdb_dataset.shuffle()\n",
    "train_dataset = dataset[:num_train]\n",
    "test_dataset = dataset[num_train:]\n",
    "\n",
    "# Create data loaders for datasets\n",
    "bs = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
    "        super(GCNClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.fc = torch.nn.Linear(out_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # Use a constant input feature for all nodes\n",
    "        x = torch.ones(data.num_nodes, 1)  # Set all input features to 1\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_ch = 16\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Create the model and optimizer\n",
    "model = GCNClassifier(in_channels=1, hidden_channels=num_hidden_ch, out_channels=num_hidden_ch, num_classes=imdb_dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, data.y)  # Cross-entropy loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.5082\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize variables to keep track of correct predictions and total examples\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "\n",
    "# Validation Set\n",
    "for data in train_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "        _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "        train_total += data.y.size(0)  # Increment the total count\n",
    "        train_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "        \n",
    "train_accuracy = train_correct / train_total\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4533\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize variables to keep track of correct predictions and total examples\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "for data in test_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "    _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "    test_total += data.y.size(0)  # Increment the total count\n",
    "    test_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "    \n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GIN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GNN, self).__init__()\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return F.relu(x)\n",
    "\n",
    "class GINClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes):\n",
    "        super(GINClassifier, self).__init__()\n",
    "        self.conv1 = GINConv(GNN(in_channels, hidden_channels))\n",
    "        self.conv2 = GINConv(GNN(hidden_channels, out_channels))\n",
    "        self.fc = torch.nn.Linear(out_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = torch.ones(data.num_nodes, 1)  # Set all input features to 1\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden_ch = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create the model and optimizer\n",
    "model = GINClassifier(in_channels=1, hidden_channels=num_hidden_ch, out_channels=num_hidden_ch, num_classes=imdb_dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, data.y)  # Cross-entropy loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7165\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize variables to keep track of correct predictions and total examples\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "\n",
    "# Validation Set\n",
    "for data in train_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "        _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "        train_total += data.y.size(0)  # Increment the total count\n",
    "        train_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "        \n",
    "train_accuracy = train_correct / train_total\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "# Test Set\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "for data in test_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "    _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "    test_total += data.y.size(0)  # Increment the total count\n",
    "    test_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "    \n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gat2v Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATv2Classifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_classes, heads=1):\n",
    "        super(GATv2Classifier, self).__init__()\n",
    "        self.conv1 = GATv2Conv(in_channels, hidden_channels, heads=heads)\n",
    "        self.conv2 = GATv2Conv(hidden_channels * heads, out_channels, heads=heads)\n",
    "        self.fc = torch.nn.Linear(out_channels * heads, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = torch.ones(data.num_nodes, 1)  # Set all input features to 1\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model and optimizer\n",
    "num_hidden_ch = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = GATv2Classifier(in_channels=1, hidden_channels=num_hidden_ch, out_channels=num_hidden_ch, num_classes=imdb_dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "def train(model, loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.cross_entropy(out, data.y)  # Cross-entropy loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.5082\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Initialize variables to keep track of correct predictions and total examples\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "\n",
    "# Validation Set\n",
    "for data in train_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "        _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "        train_total += data.y.size(0)  # Increment the total count\n",
    "        train_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "        \n",
    "train_accuracy = train_correct / train_total\n",
    "print(f'Train Accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.4533\n"
     ]
    }
   ],
   "source": [
    "# Test Set\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "for data in test_loader:\n",
    "    with torch.no_grad():  # Disable gradient tracking during evaluation\n",
    "        out = model(data)  # Forward pass\n",
    "    _, predicted = out.max(dim=1)  # Get the predicted class labels\n",
    "    test_total += data.y.size(0)  # Increment the total count\n",
    "    test_correct += (predicted == data.y).sum().item()  # Increment the correct count\n",
    "    \n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphGPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPS(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes, num_layers, new_channels, dropout_rate=0.5):\n",
    "        super().__init__()\n",
    "        self.input_transform = Linear(num_features, new_channels)\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            conv_layer = GCNConv(new_channels, new_channels)\n",
    "            self.convs.append(GPSConv(new_channels, conv_layer))\n",
    "            self.norms.append(LayerNorm(new_channels))\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.output = Linear(new_channels, num_classes)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        def degree_feature(data):\n",
    "            deg = torch.zeros(data.num_nodes, dtype=torch.float).to(data.edge_index.device)\n",
    "            deg.index_add_(0, data.edge_index[0], torch.ones(data.edge_index.size(1), device=data.edge_index.device))\n",
    "            deg.index_add_(0, data.edge_index[1], torch.ones(data.edge_index.size(1), device=data.edge_index.device))\n",
    "            return deg.view(-1, 1)\n",
    "        \n",
    "        const_feat = torch.ones((data.num_nodes, 1))\n",
    "        deg_feat = degree_feature(data)\n",
    "        rand_feat = torch.rand((data.num_nodes, 1))\n",
    "\n",
    "        x = torch.cat([const_feat, deg_feat, rand_feat], dim=1)\n",
    "        edge_index = data.edge_index\n",
    "        batch = data.batch\n",
    "\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            x = conv(x, edge_index)\n",
    "            x = norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return F.log_softmax(self.output(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joywang/opt/anaconda3/lib/python3.9/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    }
   ],
   "source": [
    "model = GPS(num_features=imdb_dataset.num_node_features, num_classes=imdb_dataset.num_classes, \n",
    "                         num_layers=5, new_channels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    for data in train_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "for epoch in range(500):\n",
    "    train()\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "for data in train_loader:\n",
    "    _, pred = model(data).max(dim=1)\n",
    "    correct += pred.eq(data.y).sum().item()\n",
    "\n",
    "train_acc = correct / len(train_loader)\n",
    "print('Accuracy of GPS on train IMDB:', train_acc)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "for data in test_loader:\n",
    "    data = data\n",
    "    _, pred = model(data).max(dim=1)\n",
    "    correct += pred.eq(data.y).sum().item()\n",
    "\n",
    "test_acc = correct / len(test_loader)\n",
    "print('Accuracy of GPS on test IMDB:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LongRange Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PascalVOC_data = PascalVOC_dataset[0]\n",
    "num_output_ch = 16\n",
    "learning_rate = 0.01\n",
    "\n",
    "num_nodes = PascalVOC_data.num_nodes \n",
    "test_percentage = 0.1\n",
    "\n",
    "indices = torch.randperm(num_nodes)\n",
    "train_indices = indices[:int(num_nodes * (1 - test_percentage))]\n",
    "test_indices = indices[int(num_nodes * (1 - test_percentage)):]\n",
    "\n",
    "train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "train_mask[train_indices] = True\n",
    "test_mask[test_indices] = True\n",
    "\n",
    "# Add the train_mask and test_mask to your PascalVOC_data object\n",
    "PascalVOC_data.train_mask = train_mask\n",
    "PascalVOC_data.test_mask = test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, out_channels)\n",
    "        self.conv2 = GCNConv(out_channels, PascalVOC_dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = GCN(PascalVOC_data.num_node_features, num_output_ch)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7971\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "num_epochs = 200\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(PascalVOC_data)\n",
    "    loss = F.nll_loss(out[PascalVOC_data.train_mask], PascalVOC_data.y[PascalVOC_data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train(epoch)\n",
    "\n",
    "# During training, record the accuracy on the validation set.\n",
    "model.eval()\n",
    "_, pred = model(PascalVOC_data).max(dim=1)\n",
    "correct = int(pred[PascalVOC_data.train_mask].eq(PascalVOC_data.y[PascalVOC_data.train_mask]).sum().item())\n",
    "accuracy = correct / PascalVOC_data.train_mask.sum().item()\n",
    "print(f'Train Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7609\n"
     ]
    }
   ],
   "source": [
    "# find accuracy on the test set\n",
    "_, pred = model(PascalVOC_data).max(dim=1)\n",
    "correct = int(pred[PascalVOC_data.test_mask].eq(PascalVOC_data.y[PascalVOC_data.test_mask]).sum().item())\n",
    "test_accuracy = correct / PascalVOC_data.test_mask.sum().item()\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GIN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GIN, self).__init__()\n",
    "        nn1 = torch.nn.Sequential(torch.nn.Linear(in_channels, out_channels), torch.nn.ReLU(), torch.nn.Linear(out_channels, out_channels))\n",
    "        nn2 = torch.nn.Sequential(torch.nn.Linear(out_channels, out_channels), torch.nn.ReLU(), torch.nn.Linear(out_channels, cora_dataset.num_classes))\n",
    "        \n",
    "        self.conv1 = GINConv(nn1)\n",
    "        self.conv2 = GINConv(nn2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "num_output_ch = 16\n",
    "learning_rate = 0.01\n",
    "gin_model = GIN(PascalVOC_data.num_node_features, num_output_ch)\n",
    "gin_optimizer = torch.optim.Adam(gin_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.0000, Val: 0.7360, Test: 0.7500\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    gin_model.train()\n",
    "    gin_optimizer.zero_grad()\n",
    "    out = gin_model(PascalVOC_data)\n",
    "    loss = F.nll_loss(out[PascalVOC_data.train_mask], PascalVOC_data.y[PascalVOC_data.train_mask])\n",
    "    loss.backward()\n",
    "    gin_optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    gin_model.eval()\n",
    "    logits, accs = gin_model(PascalVOC_data), []\n",
    "    for _, mask in PascalVOC_data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(PascalVOC_data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "# Training the model\n",
    "for epoch in range(num_epochs):\n",
    "    train()\n",
    "    \n",
    "train_acc, val_acc, test_acc = test()\n",
    "print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GATv2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATv2(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GATv2, self).__init__()\n",
    "        self.conv1 = GATv2Conv(in_channels, out_channels, heads=1)\n",
    "        self.conv2 = GATv2Conv(out_channels, cora_dataset.num_classes, heads=1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "gatv2_model = GATv2(PascalVOC_data.num_node_features, num_output_ch)\n",
    "gatv2_optimizer = torch.optim.Adam(gatv2_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.0000, Val: 0.7360, Test: 0.7500\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    gatv2_model.train()\n",
    "    gatv2_optimizer.zero_grad()\n",
    "    out = gatv2_model(PascalVOC_data)\n",
    "    loss = F.nll_loss(out[PascalVOC_data.train_mask], PascalVOC_data.y[PascalVOC_data.train_mask])\n",
    "    loss.backward()\n",
    "    gatv2_optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    gatv2_model.eval()\n",
    "    logits, accs = gatv2_model(cora_data), []\n",
    "    for _, mask in PascalVOC_data('train_mask', 'val_mask', 'test_mask'):\n",
    "        pred = logits[mask].max(1)[1]\n",
    "        acc = pred.eq(PascalVOC_data.y[mask]).sum().item() / mask.sum().item()\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train()\n",
    "    \n",
    "print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPS(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, pe_dim=8):\n",
    "        super().__init__()\n",
    "\n",
    "        # Use linear layers for node embeddings and positional encodings\n",
    "        self.node_emb = Linear(in_channels, hidden_channels - pe_dim)\n",
    "        self.pe_lin = Linear(in_channels, pe_dim)\n",
    "        self.pe_norm = BatchNorm1d(in_channels)\n",
    "\n",
    "        self.convs = ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv_layer = GCNConv(hidden_channels, hidden_channels)\n",
    "            self.convs.append(GPSConv(hidden_channels, conv_layer))\n",
    "\n",
    "        self.mlp = Sequential(\n",
    "            Linear(hidden_channels, out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        x = self.pe_norm(x)\n",
    "        x = torch.cat((self.node_emb(x), self.pe_lin(x)), 1)\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index, batch=batch)  # Edge attributes are not passed\n",
    "        return F.log_softmax(self.mlp(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPS(in_channels=PascalVOC_data.num_node_features, hidden_channels=64, num_layers=3, out_channels=cora_dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(PascalVOC_data.x, PascalVOC_data.edge_index)\n",
    "    loss = F.nll_loss(out[PascalVOC_data.train_mask], PascalVOC_data.y[PascalVOC_data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = pred[PascalVOC_data.train_mask] == PascalVOC_data.y[PascalVOC_data.train_mask]\n",
    "    train_accuracy = int(correct.sum()) / int(PascalVOC_data.train_mask.sum())\n",
    "    \n",
    "    return train_accuracy\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(PascalVOC_data.x, PascalVOC_data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = pred[PascalVOC_data.test_mask] == PascalVOC_data.y[PascalVOC_data.test_mask]\n",
    "    return int(correct.sum()) / int(PascalVOC_data.test_mask.sum())\n",
    "\n",
    "num_epochs = 200\n",
    "final_train_acc, final_test_acc = None, None\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_acc = train()\n",
    "    test_acc = test()\n",
    "    scheduler.step(train_acc)  # Note: This should ideally be a loss value\n",
    "\n",
    "    final_train_acc = train_acc\n",
    "    final_test_acc = test_acc\n",
    "\n",
    "# Print the final training and test accuracies\n",
    "print(f'Final Train Acc: {final_train_acc:.4f}, Final Test Acc: {final_test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
